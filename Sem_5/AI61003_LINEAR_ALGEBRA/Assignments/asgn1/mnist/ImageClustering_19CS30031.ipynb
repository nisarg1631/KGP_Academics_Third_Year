{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageClustering_19CS30031.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUm7A2otpMeD"
      },
      "source": [
        "Import Libraires"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdJJi_ExoLjf"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iVFNoiNpWXu"
      },
      "source": [
        "Get and format data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdy2kJ7upLQ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d39c555-36e7-4793-e5c8-7aafc038fea3"
      },
      "source": [
        "def get_data():\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "    # reshape matrix to vector\n",
        "    x_train, x_test = x_train.reshape(x_train.shape[0], -1), x_test.reshape(x_test.shape[0], -1)\n",
        "\n",
        "    # scale values to 0-1\n",
        "    x_train = x_train/255.0\n",
        "    x_test = x_test/255.0\n",
        "\n",
        "    train_data, train_labels = [], []\n",
        "    for i in range(10):\n",
        "        train_labels += [i]*100\n",
        "        temp_data = x_train[np.where(y_train == i)[0]]\n",
        "        np.random.shuffle(temp_data)\n",
        "        train_data.extend(temp_data[:100])\n",
        "    \n",
        "    train_data, train_labels = np.array(train_data), np.array(train_labels)\n",
        "    idx = np.random.permutation(len(train_data))\n",
        "    train_data, train_labels = train_data[idx], train_labels[idx]\n",
        "\n",
        "    idx = np.random.permutation(len(x_test))\n",
        "    test_data, test_labels = x_test[idx][:50], y_test[idx][:50]\n",
        "    return (train_data, train_labels), (test_data, test_labels)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = get_data()\n",
        "print(f\"N = number of training examples = {x_train.shape[0]}\")\n",
        "print(f\"n = number of features = {x_train.shape[1]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N = number of training examples = 1000\n",
            "n = number of features = 784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOIesOwu9lxj"
      },
      "source": [
        "KMeans Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I9QQCTj9kgS"
      },
      "source": [
        "class KMeans():\n",
        "    def __init__(self, x, y, cluster_cnt = 20, random_init = 1):\n",
        "        self.data = x\n",
        "        self.labels = y\n",
        "        self.feature_len = self.data.shape[1]\n",
        "        self.train_len = self.data.shape[0]\n",
        "        self.clusters = np.zeros(self.train_len, dtype=int)\n",
        "        self.cluster_cnt = cluster_cnt\n",
        "        self.cluster_centers = np.random.uniform(size=(self.cluster_cnt, self.feature_len))\n",
        "        self.cluster_labels = -1*np.ones(self.cluster_cnt, dtype=int)\n",
        "        if random_init == 0:\n",
        "            self.cluster_centers = self.data[np.random.randint(0, self.train_len, self.cluster_cnt)]\n",
        "        self.j_clust = []\n",
        "    \n",
        "    def get_distance(self, x, y):\n",
        "        return np.linalg.norm(x-y, 2)\n",
        "    \n",
        "    def update_cluster_assignment(self):\n",
        "        for i in range(self.train_len):\n",
        "            self.clusters[i] = np.argmin(np.array([self.get_distance(self.data[i], c) for c in self.cluster_centers]))\n",
        "    \n",
        "    def update_cluster_representatives(self):\n",
        "        for i in range(self.cluster_cnt):\n",
        "            idx = np.where(self.clusters == i)[0]\n",
        "            if idx.shape[0] == 0:\n",
        "                self.cluster_centers[i] = np.zeros(self.feature_len)\n",
        "            else:\n",
        "                self.cluster_centers[i] = np.mean(self.data[idx], axis=0)\n",
        "    \n",
        "    def update_cluster_labels(self):\n",
        "        self.cluster_labels = -1*np.ones(self.cluster_cnt, dtype=int)\n",
        "        for i in range(self.cluster_cnt):\n",
        "            freq = np.bincount(self.labels[np.where(self.clusters == i)])\n",
        "            if freq.shape[0]:\n",
        "                self.cluster_labels[i]=np.argmax(freq)\n",
        "    \n",
        "    def get_j_clust(self):\n",
        "        return np.mean(np.array([self.get_distance(self.data[i], self.cluster_centers[self.clusters[i]]) for i in range(self.train_len)]))\n",
        "    \n",
        "    def check_convergence(self):\n",
        "        if len(self.j_clust) < 2:\n",
        "            return False\n",
        "        return np.absolute(self.j_clust[-1] - self.j_clust[-2]) < 1e-6\n",
        "    \n",
        "    def get_centers(self):\n",
        "        return self.cluster_centers\n",
        "    \n",
        "    def train(self, max_iterations = 1000, info = False):\n",
        "        for i in range(max_iterations):\n",
        "            self.update_cluster_assignment()\n",
        "            self.update_cluster_representatives()\n",
        "            self.update_cluster_labels()\n",
        "            self.j_clust.append(self.get_j_clust())\n",
        "            if info:\n",
        "                print(f\"Iteration {i+1}: j_clust = {self.j_clust[-1]}\")\n",
        "            if self.check_convergence():\n",
        "                print(f\"Converged after {i+1} iterations.\")\n",
        "                return self.j_clust[-1]\n",
        "        print(f\"Max iterations reached.\")\n",
        "        return self.j_clust[-1]\n",
        "    \n",
        "    def test(self, x, y):\n",
        "        predicted_clusters = np.array( [np.argmin(np.array([self.get_distance(x_i, c) for c in self.cluster_centers])) for x_i in x] )\n",
        "        predicted_values = self.cluster_labels[predicted_clusters]\n",
        "        return np.mean(np.equal(predicted_values, y))\n",
        "\n",
        "    def visualise_cluster_representatives(self):\n",
        "        dims = int(np.sqrt(self.feature_len))\n",
        "        images = self.cluster_centers.reshape((self.cluster_cnt, dims, dims))\n",
        "        fig, axs = plt.subplots(5, 4, figsize=(14, 14))\n",
        "        plt.gray()\n",
        "        for i, a in enumerate(axs.flat):\n",
        "            a.matshow(images[i])\n",
        "            a.axis('off')\n",
        "            a.text(-4.0, -2.0, f\"Value = {self.cluster_labels[i]}\")\n",
        "        fig.suptitle(\"Cluster Representatives\", fontsize=30)\n",
        "        plt.show()\n",
        "    \n",
        "    def visualise_j_clust(self):\n",
        "        plt.xlabel('Iterations')\n",
        "        plt.ylabel('J_Clust')\n",
        "        plt.plot(range(len(self.j_clust)), self.j_clust)\n",
        "        plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YR4WXqMVT-CB"
      },
      "source": [
        "Results and visualisation (Part a and b)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-XiGrbUOLX2"
      },
      "source": [
        "kmeans_trainer = KMeans(x_train, y_train) # for case(ii) pass random_init = 0\n",
        "kmeans_trainer.train()\n",
        "kmeans_trainer.visualise_cluster_representatives()\n",
        "kmeans_trainer.visualise_j_clust()\n",
        "print(f\"Accuracy is: {kmeans_trainer.test(x_test, y_test)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKpZ0CRUYE0o"
      },
      "source": [
        "Variation in number of clusters (Part c)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWBdRI4WYCYo"
      },
      "source": [
        "cluster_range = range(5, 21)\n",
        "j_clust_values = []\n",
        "for i in cluster_range:\n",
        "    kmeans_trainer = KMeans(x_train, y_train, cluster_cnt = i) # for case(ii) pass random_init = 0\n",
        "    j_clust_values.append(kmeans_trainer.train())\n",
        "\n",
        "j_clust_values = np.array(j_clust_values)\n",
        "min_j_clust = np.min(j_clust_values)\n",
        "k_min = cluster_range[np.argmin(j_clust_values)]\n",
        "print(f\"Min J_clust = {min_j_clust} for k = {k_min}\")\n",
        "for i, val in enumerate(j_clust_values):\n",
        "    print(f\"k = {i+5}, J_clust = {val}\")\n",
        "plt.xlabel('k (number of clusters)')\n",
        "plt.ylabel('J_Clust')\n",
        "plt.plot(cluster_range, j_clust_values)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}